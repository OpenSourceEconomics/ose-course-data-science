{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbsphinx": "hidden",
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-selection, heterogeneity, and causal graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Alternatives to back-door identification**\n",
    "\n",
    "The next chapters deal with:\n",
    "\n",
    "* instrumental variables\n",
    "* front-door identification with causal mechanisms\n",
    "* conditioning estimators using pretreatment variables\n",
    "\n",
    "Why do we need to consider alternatives?\n",
    "\n",
    "$\\rightarrow$selection on unobservables / nonignorability of treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What makes an unobservable?\n",
    "\n",
    "* simple confounding, stable unobserved common cause of treatment and outcome variable\n",
    "\n",
    "* subtle confounding, direct self-selection into the treatment based on accurate perceptions of \n",
    "the individual level treatment effect\n",
    "\n",
    "Selection on unobservables as a combination of two features:\n",
    "\n",
    "* treatment effect heterogeneity\n",
    "* self-selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonignorability and selection on the unobservables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Selection on observables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"material/fig-4-8.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Selection on unobservables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"material/fig-4-9.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Selection on the unobservables and the utility of additional posttreatment measures of the outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Catholic school example**\n",
    "\n",
    "* claim that Catholic schools are more effective than public schools in teaching mathematics and \n",
    "reading to equivalent High School students.\n",
    "\n",
    "* conditioning on family background and motivation to learn \n",
    "\n",
    "* those enrolling into Catholic school have the most to gain from doing so\n",
    "\n",
    "**Notation**\n",
    "\n",
    "* $Y_{10}$, observed score on standardized achievement test given in tenth grade\n",
    "\n",
    "* $D$ causal variable taking value one if student attends Catholic school\n",
    "\n",
    "* $U$ unobserved motivation to learn, differences in home environment, anticipation of causal \n",
    "effect itself\n",
    "\n",
    "* $X$ determinants of achievement tests that have no direct causal effect on school sector or selection\n",
    "\n",
    "* $O$ ultimate background variables that affect all other variables in graph\n",
    "\n",
    "We proceed in two steps:\n",
    "\n",
    "* assess identification for given directed graphs\n",
    "\n",
    "* examine structure of directed graph itself\n",
    "\n",
    "<img src=\"material/fig-8-1.png\" width=\"500\" />\n",
    "\n",
    "We cannot identify the causal effect of $D$ on $Y_{10}$ in subfigure (a) but in subfigure (b).\n",
    "However, at what cost?\n",
    "\n",
    "$Y_{10}$ blocks all back-door paths, however it does not satisfy the Condition 2 of the back-door criterion. As such, it adjusts away \n",
    "some of the total causal effect of $D$ on $Y_{12}$.\n",
    "\n",
    "Let $E$ denote an student's ability for test taking and allow for the direct effect of $U$ on bow both achievement scores. Then maybe this is a more complete picture?\n",
    "\n",
    "<img src=\"material/fig-8-2.png\" width=\"500\" />\n",
    "\n",
    "Back-door adjustment by $Y_{10}$ ineffective again after revisiting economic implications of the \n",
    "imposed graph. In fact, $Y_{10}$ is now a collider variable that induces a noncausal dependence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Panel Data Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The motivation behind this example is simply to show that we cannot learn anything about the \n",
    "underlying causal effect with the conventional strategies and how we model self-selection in the \n",
    "data generating process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_propensity_score(o, u):\n",
    "    \"\"\"Get the propensity score.\"\"\"\n",
    "    level = -3.8 + o + u\n",
    "    return np.exp(level) / (1 + np.exp(level))\n",
    "\n",
    "\n",
    "def get_treatment_status(o, u):\n",
    "    \"\"\"Sampling treatment status\"\"\"\n",
    "    # Following the causal graph, the treatment indicator is only a function\n",
    "    # of the background characteristics O and the unobservable U.\n",
    "    p = get_propensity_score(o, u)\n",
    "    return np.random.choice([1, 0], p=[p, 1 - p])\n",
    "\n",
    "\n",
    "def get_covariates():\n",
    "    \"\"\" Get covariates.\"\"\"\n",
    "    o, e = np.random.normal(size=2)\n",
    "    x, u = o + np.random.normal(size=2)\n",
    "    return o, u, x, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_potential_outcomes(grade, o, x, e, u, scenario=0, selection=False):\n",
    "    \"\"\"Get potential outcomes.\n",
    "    \n",
    "    Sampling of potential outcome of an individual for the panel data demonstration.\n",
    "    \n",
    "    Args:\n",
    "        grade: an integer for the grade the individual is in.\n",
    "        o, x, e : floats of observable characteristics.\n",
    "        u: a float of unobservable characteristic.\n",
    "        scenario: an integer for the scenario: (0) no role for E, (1) role for E.\n",
    "        selection: a boolean indicating whether there is selection on unobservables.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple of potential outcomes (Y_0, Y_1).\n",
    "    \n",
    "    \"\"\"\n",
    "    # We want to make sure we only pass in valid input.\n",
    "    assert scenario in range(2)\n",
    "    assert selection in [True, False]\n",
    "    assert grade in [10, 11, 12]\n",
    "\n",
    "    # There is a natural progression in test scores.\n",
    "    level = dict()\n",
    "    level[10] = 100\n",
    "    level[11] = 101\n",
    "    level[12] = 102\n",
    "\n",
    "    if scenario == 0:\n",
    "        y_0 = level[grade] + o + u + x + np.random.normal()\n",
    "    elif scenario == 1:\n",
    "        y_0 = level[grade] + o + u + x + e + np.random.normal()\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # Sampling of treatment effects. The key difference for selection on unobservables is in how\n",
    "    # the overall treatment effect depends on the  unobservable U that also affects the choice\n",
    "    # probability. This was the major criticism of Coleman's work.\n",
    "    delta_1 = np.random.normal(loc=10, scale=1)\n",
    "    if selection:\n",
    "        delta_2 = np.random.normal(loc=u)\n",
    "    else:\n",
    "        delta_2 = np.random.normal()\n",
    "\n",
    "    if grade == 10:\n",
    "        y_1 = y_0 + delta_1 + delta_2\n",
    "    elif grade == 11:\n",
    "        y_1 = y_0 + (1 + delta_1) + delta_2\n",
    "    elif grade == 12:\n",
    "        y_1 = y_0 + (2 + delta_1) + delta_2\n",
    "\n",
    "    return y_0, y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_sample_panel_demonstration(num_agents=1000, scenario=0, selection=False, seed=123):\n",
    "    \"\"\"Get sample for demonstration.\n",
    "    \n",
    "    Create a random sample for the demonstration of the usefulness of (or lack thereof) of having\n",
    "    additional posttreatment measures of the outcome.\n",
    "    \n",
    "    Args:\n",
    "        num_agents: an integer for the number of agents in the sample\n",
    "        scenario: an integer that indicates whether to include E as a determinant of test scores\n",
    "        selection: a boolean variable indicating whether selection on unobservables is an issue\n",
    "        seed: an integer setting the random seed\n",
    "        \n",
    "    Returns:\n",
    "        A dataframe with the simulated sample.\n",
    "    \n",
    "    \"\"\"\n",
    "    # We first initialize an empty DataFrame that holds the information for each individual\n",
    "    # and each time period.\n",
    "    columns = [\"Y\", \"D\", \"O\", \"X\", \"E\", \"U\", \"Y_1\", \"Y_0\"]\n",
    "    index = product(range(num_agents), [10, 11, 12])\n",
    "    index = pd.MultiIndex.from_tuples(index, names=(\"Identifier\", \"Grade\"))\n",
    "    df = pd.DataFrame(columns=columns, index=index)\n",
    "\n",
    "    # Now we are ready to simulate the sample with the desired characteristics.\n",
    "    np.random.seed(seed)\n",
    "    for i in range(num_agents):\n",
    "\n",
    "        o, u, x, e = get_covariates()\n",
    "        d = get_treatment_status(o, u)\n",
    "        for grade in [10, 11, 12]:\n",
    "            y_0, y_1 = get_potential_outcomes(grade, o, x, e, u, scenario, selection)\n",
    "            y = d * y_1 + (1 - d) * y_0\n",
    "            df.loc[(i, grade), :] = [y, d, o, x, e, u, y_1, y_0]\n",
    "\n",
    "    # Finally some type definitions for pretty output.\n",
    "    df = df.astype(np.float)\n",
    "    df = df.astype({\"D\": np.int})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>D</th>\n",
       "      <th>O</th>\n",
       "      <th>X</th>\n",
       "      <th>E</th>\n",
       "      <th>U</th>\n",
       "      <th>Y_1</th>\n",
       "      <th>Y_0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifier</th>\n",
       "      <th>Grade</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>10</th>\n",
       "      <td>95.841898</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.085631</td>\n",
       "      <td>-0.802652</td>\n",
       "      <td>0.997345</td>\n",
       "      <td>-2.591925</td>\n",
       "      <td>105.586179</td>\n",
       "      <td>95.841898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>98.499140</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.085631</td>\n",
       "      <td>-0.802652</td>\n",
       "      <td>0.997345</td>\n",
       "      <td>-2.591925</td>\n",
       "      <td>106.765876</td>\n",
       "      <td>98.499140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>97.072351</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.085631</td>\n",
       "      <td>-0.802652</td>\n",
       "      <td>0.997345</td>\n",
       "      <td>-2.591925</td>\n",
       "      <td>110.597380</td>\n",
       "      <td>97.072351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>10</th>\n",
       "      <td>97.544210</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.619191</td>\n",
       "      <td>-0.042445</td>\n",
       "      <td>-0.769433</td>\n",
       "      <td>-0.492665</td>\n",
       "      <td>108.934451</td>\n",
       "      <td>97.544210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100.583068</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.619191</td>\n",
       "      <td>-0.042445</td>\n",
       "      <td>-0.769433</td>\n",
       "      <td>-0.492665</td>\n",
       "      <td>112.137966</td>\n",
       "      <td>100.583068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Y  D         O         X         E         U  \\\n",
       "Identifier Grade                                                          \n",
       "0          10      95.841898  0 -1.085631 -0.802652  0.997345 -2.591925   \n",
       "           11      98.499140  0 -1.085631 -0.802652  0.997345 -2.591925   \n",
       "           12      97.072351  0 -1.085631 -0.802652  0.997345 -2.591925   \n",
       "1          10      97.544210  0 -0.619191 -0.042445 -0.769433 -0.492665   \n",
       "           11     100.583068  0 -0.619191 -0.042445 -0.769433 -0.492665   \n",
       "\n",
       "                         Y_1         Y_0  \n",
       "Identifier Grade                          \n",
       "0          10     105.586179   95.841898  \n",
       "           11     106.765876   98.499140  \n",
       "           12     110.597380   97.072351  \n",
       "1          10     108.934451   97.544210  \n",
       "           11     112.137966  100.583068  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_agents, scenario, selection = 1000, 0, False\n",
    "df = get_sample_panel_demonstration(num_agents, scenario, selection)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is the average treatment effect and how does it depend on the presence of selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Selection False\n",
      " Grade 10:  ATE 10.090\n",
      " Grade 12:  ATE 12.014\n",
      "\n",
      "\n",
      " Selection True\n",
      " Grade 10:  ATE 10.116\n",
      " Grade 12:  ATE 12.039\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_agents, scenario = 1000, 0\n",
    "\n",
    "# This setup allows to freeze some arguments of the function\n",
    "# that do not change during the analysis.\n",
    "from functools import partial  # noqa: E402\n",
    "\n",
    "simulate_sample = partial(get_sample_panel_demonstration, num_agents, scenario)\n",
    "\n",
    "for selection in [False, True]:\n",
    "    print(f\" Selection {selection}\")\n",
    "    df = simulate_sample(selection)\n",
    "    for grade in [10, 12]:\n",
    "        df_grade = df.loc[(slice(None), grade), :]\n",
    "        stat = (df_grade[\"Y_1\"] - df_grade[\"Y_0\"]).mean()\n",
    "        print(f\" Grade {grade}:  ATE {stat:5.3f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The average treatment effects are unaffected by selection. But how does the picture change when we look at subsets of the population?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Selection False\n",
      " Grade 10:  ATC  10.098   ATT  10.012\n",
      " Grade 12:  ATC  12.001   ATT  12.134\n",
      "\n",
      "\n",
      " Selection True\n",
      " Grade 10:  ATC   9.958   ATT  11.655\n",
      " Grade 12:  ATC  11.861   ATT  13.776\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for selection in [False, True]:\n",
    "    print(f\" Selection {selection}\")\n",
    "    df = simulate_sample(selection)\n",
    "    for grade in [10, 12]:\n",
    "        subset = df.loc[(slice(None), grade), :]\n",
    "\n",
    "        stat = list()\n",
    "        for status in range(2):\n",
    "            df_status = subset.query(f\"D == {status}\")\n",
    "            stat.append((df_status[\"Y_1\"] - df_status[\"Y_0\"]).mean())\n",
    "\n",
    "        print(\" Grade {:}:  ATC {:7.3f}   ATT {:7.3f}\".format(grade, *stat))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade: 10  Model: Y ~ D\n",
      "   Estimated Treatment Effect: 12.650\n",
      "\n",
      "Grade: 10  Model: Y ~ D + X + O\n",
      "   Estimated Treatment Effect: 10.315\n",
      "\n",
      "Grade: 12  Model: Y ~ D\n",
      "   Estimated Treatment Effect: 14.731\n",
      "\n",
      "Grade: 12  Model: Y ~ D + X + O\n",
      "   Estimated Treatment Effect: 12.466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for grade in [10, 12]:\n",
    "    for model in [\"Y ~ D\", \"Y ~ D + X + O\"]:\n",
    "        df_grade = df.loc[(slice(None), grade), :]\n",
    "        rslt = smf.ols(formula=model, data=df_grade).fit()\n",
    "        stat = rslt.params[\"D\"]\n",
    "        print(\"Grade: {}  Model: {:}\".format(*[grade, model]))\n",
    "        print(\"   Estimated Treatment Effect: {:5.3f}\\n\".format(stat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "None of the estimates come even close to our parameters of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Causal graphs for complex patterns of self-selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make sure that complex patterns of self-selection can be represented by directed graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate graphs for separate latent classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Groups**\n",
    "\n",
    "* $G=1$, selection of schools mainly for lifestyle reasons, proximity to home and taste for \n",
    "school cultures\n",
    "\n",
    "* $G=2$, selection of schools to maximize expected achievement\n",
    "\n",
    "<img src=\"material/fig-8-3.png\" width=\"500\" />\n",
    "\n",
    "\n",
    "What are the economic mechanisms are represented by each of the arrows? Why would we expect them \n",
    "to differ across the two groups?\n",
    "\n",
    "* families of the second group are more likely to send their children to charter schools $d_2 > d_1$\n",
    "\n",
    "* parents with higher levels of education are more likely to send their children to charter  schools\n",
    " as they value distinctive forms of education $\\alpha_1, \\alpha_2 > 0$ and are able to support \n",
    " their children with their homework $\\beta_1, \\beta_2 > 0$.\n",
    "\n",
    "* existing research suggests $\\delta_1, \\delta_2 > 0$ and $\\delta_2 > \\delta_1$ as families in \n",
    "second group put more effort in matching their children to schools\n",
    "\n",
    "What happens if we block the back-door path by conditioning in $P$ but ignore the existence of \n",
    "two latent classes? If $P$ is associated with latent class membership, then we do not properly \n",
    "weigh the stratum-specific treatment effects as there is heterogeneity within strata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A single graph that represents all latent classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now let $G$ capture effect heterogeneity.\n",
    "\n",
    "<img src=\"material/fig-8-4.png\" width=\"500\" />\n",
    "\n",
    "We outline more and more elaborate ideas about the economic mechanisms that determine class membership and how they modify the structure of the causal graph.\n",
    "\n",
    "* **no arrow from $P$ to $G$** implies that students with students who have higher levels of education are no more likely to know of the educational policy dialogue hat claims that charter schools have advantages. \n",
    "\n",
    "* **no arrow from $G$ to $Y$** implies that there is in fact (on average) no treatment effect heterogeneity.\n",
    "\n",
    "<img src=\"material/fig-8-5.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self-selection into the latent class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now elaborate on the mechanism that determines class membership. We assume that $G$ is at least in part determined by a variable that measures a family's subjective expectations of their child's likely benefit from attending a charter school instead of a regular school.\n",
    "\n",
    "<img src=\"material/fig-8-6.png\" width=\"500\" />\n",
    "\n",
    "However, these expectations are potentially based on access to information that is often related to parental background."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
