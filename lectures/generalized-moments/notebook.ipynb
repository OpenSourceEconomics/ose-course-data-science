{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# fancy imports\n",
    "from scipy.optimize import minimize\n",
    "from linearmodels.iv import IV2SLS\n",
    "from functools import partial\n",
    "from scipy.stats import norm\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized method of moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generalized method of moments (GMM) is a general estimation principle, where the estimators are derived from so-called moment conditions. It provides a unifying framework for the comparison of alternative estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure:\n",
    "- Setup\n",
    "- Identification\n",
    "- Asymptotic distribution\n",
    "- Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notation:**\n",
    "\n",
    "- $\\beta$ $(p \\times 1)$ - parameter vector\n",
    "- $w_i$ $(i = 1,..., n)$ - data points\n",
    "- $g_i(w_i, \\beta)$ $m \\times 1$ - moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GMM estimator is based on a model where, for the true parameter value $\\beta_0$ the moment conditions $E[g_i (\\beta_0)] = 0$ are satisfied.\n",
    "\n",
    "The estimator is formed by choosing $\\beta$ so that the sample average of $g_i(\\beta)$ is close to\n",
    "its zero population value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimator is formed by choosing β so that the sample average of gi(β) is close to its zero population value.\n",
    "Let\n",
    "\n",
    "$$\\hat{g}(\\beta) = \\frac{1}{n} \\sum_{i=1}^n g_i(\\beta)$$\n",
    "\n",
    "-  theoretical moments\n",
    "- empirical moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\hat{A}$ denote a $m \\times m$ positive semi-definite matrix, then the GMM estimator is given by\n",
    "\n",
    "$$\\hat{\\beta} = \\underset{\\beta}{\\operatorname{argmin}} \\hat{g}(\\beta)^\\prime\\,\\hat{A}\\,\\hat{g}(\\beta)$$\n",
    "\n",
    "The GMM estimator chooses $\\hat{\\beta}$ so the sample average $\\hat{g}(\\beta)$ is close to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instrumental variables**\n",
    "\n",
    "Let’s work through an example on the blackboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unifying framework**\n",
    "\n",
    "Many other popular estimation strategies can be analyzed in a GMM setup:\n",
    "\n",
    "- Ordinary least squares $E[x_i (y_i - x_i \\beta_0)] = 0 $\n",
    "- Instrumental variables $E[z_i (y_i - x_i \\beta_0)] = 0 $\n",
    "- Maximum likelihood $E[\\partial \\ln f(x_i, \\beta_0) / \\partial\\beta] = 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If moments cannot be evaluated analytically then we have an application of the method of simulated moments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distance and weighing matrix**\n",
    "\n",
    "Let’s look at the role of the weighing matrix for a two dimensional example:\n",
    "\n",
    "- identity matrix \n",
    "\\begin{align*} Q(\\beta) = \n",
    "\\left(\\begin{matrix}\n",
    "g_1 & g_2\n",
    "\\end{matrix}\\right)\n",
    "\\left(\\begin{matrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{matrix}\\right)\n",
    "\\left(\\begin{matrix}\n",
    "g_1 \\\\\n",
    "g_2\n",
    "\\end{matrix}\\right) = g_1^2 + g_2^2\n",
    "\\end{align*}\n",
    "\n",
    "- alternative\n",
    "\\begin{align*}Q(\\beta) =\n",
    "\\left(\\begin{matrix}\n",
    "g_1 & g_2\n",
    "\\end{matrix}\\right)\n",
    "\\left(\\begin{matrix}\n",
    "2 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{matrix}\\right)\n",
    "\\left(\\begin{matrix}\n",
    "g_1 \\\\\n",
    "g_2\n",
    "\\end{matrix}\\right) = 2 \\dot g_1^2 + g_2^2\n",
    "\\end{align*}\n",
    "\n",
    "Our alternative attaches more weight to the first coordinate in the distance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters $\\beta_0$ are identified if $\\beta_0$ is the only solution to  $E[g_i(\\beta)] = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"material/fig-single-zero.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"material/fig-multiple-zero.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary condition for identification is that $m \\geq p$. When $m \\leq p$, i.e. there are fewer equations to solve than parameters, there will typically be multiple solutions to the moment conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $G = E[\\partial g_i(\\beta_0) / \\partial \\beta]$. Rank condition is $rank(G) = p$. Necessary and sufficient for identification when $g_i(\\beta)$ is linear in $\\beta$.\n",
    "\n",
    "In the general nonlinear case it is difficult to specify conditions for uniqueness of the solution to $E[g_i(\\beta)] = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $m = p$, exact identification, $\\hat{g}(\\hat{\\beta}) = 0$ asymptotically\n",
    "- $m > p$, overidentification, $\\hat{g}(\\hat{\\beta}) > 0$ asymptotically\n",
    "\n",
    "In the case of overidentification, the choice of A matters and affects the estimator’s asymptotic distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asymptotic distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Asymptotic distribution**\n",
    "\n",
    "Under some regularity conditions, the GMM estimator has the following asymptotic distribution.\n",
    "\n",
    "\\begin{align*}\n",
    "\\sqrt{n}(\\hat{\\beta} - \\beta_0) \\xrightarrow{d} \\mathbb{N}(0, V),\n",
    "\\end{align*}\n",
    "\n",
    "where $V = (G^\\prime A G)^{-1} G^\\prime A \\Omega A G (G^\\prime A G)^{-1}$ with $G = E[\\partial g_i(\\beta_0) / \\partial \\beta]$ and $\\Omega = E[g_i(\\beta_0)g_i(\\beta_0)^\\prime]$.\n",
    "\n",
    "$\\Rightarrow$ asymptotic variance depends on the choice of the weighing matrix $A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal weighing matrix $A = \\Omega^{-1}$ the asymptotic variance simplifies to\n",
    "\n",
    "\\begin{align*}\n",
    "V = (G^\\prime  \\Omega^{-1} G)^{-1}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "What makes a good moment?\n",
    "\n",
    "- small $\\Omega$, small sample variation of the moment\n",
    "- large $G$, moment informative on true value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weak identification:\n",
    "    \n",
    "<img src=\"material/fig-weak-identification.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharp identification:\n",
    "    \n",
    "<img src=\"material/fig-sharp-identification.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instrumental variables**\n",
    "\n",
    "Let’s continue our example on the blackboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important statistic for GMM is the test of overidentifying restrictions that is given by\n",
    "\n",
    "\\begin{align*}\n",
    "T = n\\,\\hat{g}(\\hat{\\beta})^\\prime \\,\\hat{\\Sigma}^{-1}\\,\\hat{g}(\\hat{\\beta})\n",
    "\\end{align*}\n",
    "\n",
    "which converges in distribution to\n",
    "\n",
    "\\begin{align*}\n",
    "T \\xrightarrow{d} \\chi^2(m - p)\n",
    "\\end{align*}\n",
    "\n",
    "under $H_0$ that the model is correctly specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Density of $\\chi^2(2)$:\n",
    "\n",
    "<img src=\"material/fig-chi-square-critical.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Density of $\\chi^2(m - p)$:\n",
    "\n",
    "<img src=\"material/fig-chi-square-degrees.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feasible efficient GMM**\n",
    "\n",
    "The optimal weighing matrix depends on moment evaluations at $\\beta_0$ which is unknown.\n",
    "- iterated feasible GMM\n",
    "- continuously updating GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Example 1** We study a simulated sample that can be estimated by ordinary least squares regression to illustrate its unifying principles.\n",
    "\n",
    "* **Example 2** We study a simulated sample that can be estimated by instrumental variables methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_1(num_agents, beta, seed=123):\n",
    "\n",
    "    random_sampling = partial(np.random.normal, size=num_agents)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    X = random_sampling(scale=10)\n",
    "    eps = random_sampling()\n",
    "\n",
    "    Y = 1 + beta * X + eps\n",
    "\n",
    "    index = pd.Index(range(num_agents), name=\"Identifier\")\n",
    "    columns = [\"Y\", \"X\"]\n",
    "    df = pd.DataFrame(np.vstack((Y, X)).T, columns=columns, index=index)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_moments(df, beta):\n",
    "    residuals = df[\"Y\"] - (1 + beta * df[\"X\"])\n",
    "    moments = df[\"X\"] * residuals\n",
    "    return np.mean(moments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the empirical moment at the truth change as we increase the sample size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta, rslt = 0.2, list()\n",
    "\n",
    "# We iterate over different sample sizes.\n",
    "grid = np.linspace(100, 1000000, num=100, dtype=int)\n",
    "for num_agents in grid:\n",
    "\n",
    "    # We simulate a sample and compute the residuals a\n",
    "    moment = get_moments(get_sample_1(num_agents, beta), beta)\n",
    "    rslt.append(moment)\n",
    "\n",
    "ax = plt.plot(rslt)\n",
    "plt.axhline(y=0, color=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does a GMM estimation look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_sample_1(num_agents=10000, beta=7)\n",
    "\n",
    "\n",
    "def criterion_function_gmm(beta, df):\n",
    "    moments = get_moments(df, beta)\n",
    "    # Where is weighting matrix?:\n",
    "    return np.square(np.mean(moments))\n",
    "\n",
    "\n",
    "rslt = minimize(criterion_function_gmm, 0.0, args=(df,), method=\"BFGS\")\n",
    "rslt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does an OLS estimation look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt = smf.ols(\"Y ~ X\", data=df).fit()\n",
    "print(\"OLS Estimate \", \"{:5.7f}\".format(rslt.params[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does a standard MLE estimation look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_residuals(df, beta):\n",
    "    residuals = df[\"Y\"] - (1 + beta * df[\"X\"])\n",
    "    return residuals\n",
    "\n",
    "\n",
    "def criterion_function_mle(beta, df):\n",
    "    residuals = get_residuals(df, beta)\n",
    "    rslt = np.clip(np.log(norm.pdf(residuals)), -10e6, None)\n",
    "    return -np.mean(rslt)\n",
    "\n",
    "\n",
    "rslt = minimize(criterion_function_mle, 0.0, args=(df,), method=\"Powell\")\n",
    "rslt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_2(num_agents, beta, seed=123):\n",
    "\n",
    "    # Setup of sample simulation\n",
    "    random_sampling = partial(np.random.normal, size=num_agents)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Create canvas for data frame\n",
    "    index = pd.Index(range(num_agents), name=\"Identifier\")\n",
    "    columns = [\"Y\", \"X\", \"Z1\", \"Z2\"]\n",
    "    df = pd.DataFrame(columns=columns, index=index)\n",
    "\n",
    "    for label in [\"Z1\", \"Z2\"]:\n",
    "        df[label] = random_sampling(scale=10)\n",
    "    C = random_sampling(scale=10)\n",
    "\n",
    "    df[\"X\"] = C + df[[\"Z1\", \"Z2\"]].sum(axis=1) + random_sampling()\n",
    "    U = C + random_sampling()\n",
    "\n",
    "    df[\"Y\"] = 1 + beta * df[\"X\"] + U\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = get_sample_2(num_agents=10000, beta=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does an OLS estimate look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt = smf.ols(\"Y ~ X\", data=df).fit()\n",
    "print(\"OLS Estimate \", \"{:5.3f}\".format(rslt.params[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt = IV2SLS.from_formula(\"Y ~ 1 + [X ~ Z1 + Z2]\", df).fit()\n",
    "print(\"IV Estimate \", \"{:5.3f}\".format(rslt.params[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does a GMM estimation look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moments(df, beta):\n",
    "    residuals = df[\"Y\"] - (1 + beta * df[\"X\"])\n",
    "\n",
    "    moments = list()\n",
    "    for label in [\"Z1\", \"Z2\"]:\n",
    "        moments.append(np.mean(df[label] * residuals))\n",
    "\n",
    "    return moments\n",
    "\n",
    "\n",
    "def criterion_function_gmm(beta, df, weighing_matrix=np.identity(2)):\n",
    "    moments = get_moments(df, beta)\n",
    "    rslt = np.dot(np.dot(moments, weighing_matrix), moments)\n",
    "    return rslt\n",
    "\n",
    "\n",
    "rslt = minimize(criterion_function_gmm, 0.0, args=(df), method=\"Powell\")\n",
    "print(\"GMM Estimate \", list(map(\"{:5.3f}\".format, rslt.x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* **Davidson, R., and  MacKinnon, J. G. (2003)**. [Econometric theory and methods](https://global.oup.com/ushe/product/econometric-theory-and-methods-9780195123722?cc=pt&lang=en&). New York: *Oxford University Press*.\n",
    "\n",
    "* **Hall, A. A. (2005)**. [Generalized method of moments](https://global.oup.com/academic/product/generalized-method-of-moments-9780198775201?cc=pt&lang=en&). New York: *Oxford University Press*.\n",
    "\n",
    "* **Whitney Newey (Fall 2007)**. [MIT OpenCourseWare](http://ocw.mit.edu), Course materials for 14.385 Nonlinear Econometric Analysis, *MIT*."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
