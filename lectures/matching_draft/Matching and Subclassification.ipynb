{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37cd8860",
   "metadata": {},
   "source": [
    "# Matching and Subclassification\n",
    "----------------\n",
    "\n",
    "Readings:\n",
    "\n",
    "* **Cunningham, S. (2021)**. Causal Inference: The Mixtape. *Yale University Press, United States*.\n",
    "\n",
    "* **Huntington-Klein, N. (2021)**. The Effect: An Introduction to Research Design and Causality. *Taylor & Francis Ltd, United Kingdom*.\n",
    "-------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abfcc8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install plotnine\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import statsmodels.api as sm \n",
    "import statsmodels.formula.api as smf \n",
    "from itertools import combinations \n",
    "import plotnine as p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dfe327",
   "metadata": {},
   "source": [
    "## Roadmap\n",
    "\n",
    "* 1. Introduction\n",
    "* 2. Subclassification\n",
    " * 2.1. Background\n",
    " * 2.2. Identifying Assumptions\n",
    " * 2.3. Example\n",
    " * 2.4. Course of dimensionality\n",
    "* 3. Exact Matching\n",
    "* 4. Approximate Matching\n",
    " * 4.1. Nearest neighbor covariate matching\n",
    " * 4.2. Bias Correction\n",
    "* 5. Propensity score methods\n",
    " * 5.1. Example\n",
    " * 5.2.Weighting on the propensity score\n",
    " * 5.3. Nearest-neighbor matching\n",
    " * 5.4. Coarsened exact matching\n",
    "* 6. Conclusion\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d83d9f",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Matching is the process of closing back door paths between the treatment and outcome variable by constructing comparison groups that are similar in a one or more matching variables. In other words and assuming $W$ is the variable causing a back door path, then choosing a sample in which there is no variation in $W$ automatically closes any open back doors created by $W$.\n",
    "\n",
    "Consider the following basic example: we are interested in estimating the effect of a job-training program on the probability of getting a job. The pool of people eligible for the program is about 50% male and 50% female, but the program was advertised strongly towards men, so the people who *actually* took part of the program were 80% men, 20% female. There is, therefore, a back door path created by the variable *gender*, so \n",
    "$Getting \\: a \\: Job\t\\leftarrow Gender \\rightarrow Job \\: Training \\: Program$. \n",
    "\n",
    "The basic idea of the matching approach then is to construct a comparable control group that was also 80% men and 20% female. Comparing these treated and untreated groups, we eliminate the gender difference so $Gender \\rightarrow JobTrainingProgram$ disappears and we can then identify $Job \\: Training \\: Program \\rightarrow Getting \\: a \\:Job$ (assuming there are no other open back door paths). \n",
    "\n",
    "In what follows, we will discuss three different types of conditional strategies: subclassification, exact matching and appropiate matching. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f95148",
   "metadata": {},
   "source": [
    "## 2. Subclassification\n",
    "\n",
    "Subclassification is a method for closing back door paths by weighting difference in means by strata-specific weights. These strata-specific weights will, in turn, adjust the differences in means so that their distribution by strata is the same as that of the counterfactual’s strata. This method then achieves distributional *balance* between the treatment and control groups in terms of the observable confounder $W$. \n",
    "\n",
    "One of the key concepts for this chapter is the Conditional Independence Assumption (CIA):\n",
    "\n",
    "$\n",
    "(Y^1, Y^0) \\perp D, X\n",
    "$\n",
    "\n",
    "which means that the expected values of $Y^1, Y^0$ are equal for both the treatment and control group for each value of $X$.\n",
    "\n",
    "\\begin{equation}\n",
    "E[Y^1| D=1, X]= E[Y^1| D=0, X]\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "E[Y^0| D=1, X]= E[Y^0| D=0, X]\n",
    "\\end{equation}\n",
    "\n",
    "CIA means you have found a conditioning strategy that satisfies the backdoor criterion and $X$ can be a $nxk$ matrix of conditioning variables that satisfies the CIA assumption.\n",
    "\n",
    "### 2.1. Background\n",
    "\n",
    "From 1860 to 1950, the rate of lung cancer incidence appeared to be increasing and studies sugested that smoking was the **cause**. For example, studies found that the relationship between daily smoking and lung cancer in males was monotonically increasing in the number of cigarettes a male smoked per day. But maybe people who smoked were different from non-smokers in features that were related to the incidence of having or not lung cancer. If the independence assumption does not hold, then computing the difference in means from smokers and non-smokers will be biased.\n",
    "\n",
    "For the following example, we follow Cochran (1968), a study trying to adress patterns in smoking data by adjusting for possible cofounders. The following table shows mortality rates by country and the type of smoking of individuals:\n",
    "\n",
    "\n",
    "![title](Material/table1.png)\n",
    "\n",
    "The table suggests that pipes and cigars are more dangerous than cigarette smoking (which does not make much sense). Recall the independence assumption and think whether it should hold:\n",
    "\n",
    "$ E[Y^1|Cigarette]=E[Y^1|Pipe]=E[Y^1|Cigar]$\n",
    "\n",
    "$ E[Y^0|Cigarette]=E[Y^0|Pipe]=E[Y^0|Cigar]$\n",
    "\n",
    "If this holds, then it means that there is *balance* in covariates, which means that the covariates are the same for each group. Lets look into the mean ages of the different groups:\n",
    "\n",
    "![title](Material/table2.png)\n",
    "\n",
    "Here we see that cigar and pipe smokers are considerably older than cigar smokers for this particular dataset, which could be a reason why the death rates are higher among cigar and pipe smokers (since older people die at a higher rate for other reasons than smoking cigars). This could also be the reason why cigar smokers present a lower death rate, since they are on average younger.\n",
    "\n",
    "Thus, we have a backdoor path that its open, and the CIA assumption is then violated. Also, the distribution of age for each group is different, leading to a covariate *imbalance*. A way to control for this is using subclassification. An example: 1) divide age into the following strata: 20-40; 41-70; 71 and older; 2) calculate the mortality rate for a treatment group (cigarette smokers) by strata; 3) weight the mortality rate for the treatment group by a strata-spefific weight that corresponds to the control group. With this procedure we achieve age-adjusted mortality rate for the treatment group.\n",
    "\n",
    "![title](Material/table3.png)\n",
    "\n",
    "Lets compute first the average death rate for pipe smokers without subclassification, where the weight is given by $\\frac{N_t}{N}$:\n",
    "\n",
    "$ 20 * \\frac{75}{100} + 40 * \\frac{25}{100} + 60 * \\frac{10}{100}= 29$ \n",
    "\n",
    "With subclassification, we want to multiply each age-specific mortality rate by the proportion of individuals in that age strata for the comparision group:\n",
    "\n",
    "$ 20 * \\frac{10}{100} + 40 * \\frac{25}{100} + 60 * \\frac{65}{100}= 51$ \n",
    "\n",
    "Recalculating the mortality rates by adjusting for the age distribution, Cochran gets:\n",
    "\n",
    "![title](Material/table4.png)\n",
    "\n",
    "### 2.2. Identifying Assumptions\n",
    "\n",
    "1. $(Y^1, Y^0) \\perp D| X$ (conditional independence)\n",
    "\n",
    "2. $ 0 < Pr(D=1|X) <1 $ (common support)\n",
    "\n",
    "The two assumptions yield:\n",
    "\n",
    "\\begin{align*}\n",
    "E[Y^1-Y^0| X] & = E[Y^1 - Y^0| X, D=1] \\\\\n",
    "&=  E[Y^1| X, D=1] - E[Y^0| X, D=0] \\\\\n",
    "&=  E[Y| X, D=1] - E[Y| X, D=0]\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "And giving the common support assumption, we get:\n",
    "\n",
    "$\\hat{\\delta_{ATE}}= \\int (E[Y|X, D=1] - E[Y|X, D=0])d Pr(X)$\n",
    "\n",
    "### 2.3. Exercise\n",
    "\n",
    "We want to explore the question on whether or not being seated first class made someone more likely to survive. Being in first class is likely to explain the probability of survival; however, we encounter two backdoor paths: being a woman and being a child.\n",
    "\n",
    "Here we will calculate a naïve simple difference in outcomes for the sample:\n",
    "\n",
    "$E[Y|D=1]-E[Y|D=0]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faef289a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class     age  sex survived\n",
       "0  1st class  adults  man      yes\n",
       "1  1st class  adults  man      yes\n",
       "2  1st class  adults  man      yes\n",
       "3  1st class  adults  man      yes\n",
       "4  1st class  adults  man      yes"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_stata(\"Data/titanic.dta\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d260a449",
   "metadata": {},
   "source": [
    "We create a variable for treated group based on the survival status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bed18b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>survived</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class     age  sex survived  d\n",
       "0  1st class  adults  man      yes  1\n",
       "1  1st class  adults  man      yes  1\n",
       "2  1st class  adults  man      yes  1\n",
       "3  1st class  adults  man      yes  1\n",
       "4  1st class  adults  man      yes  1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['d'] = 0\n",
    "titanic.loc[titanic['class']=='1st class', 'd'] = 1\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03d165f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>survived</th>\n",
       "      <th>d</th>\n",
       "      <th>sex_d</th>\n",
       "      <th>age_d</th>\n",
       "      <th>survived_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class     age  sex survived  d  sex_d  age_d  survived_d\n",
       "0  1st class  adults  man      yes  1      1      1           1\n",
       "1  1st class  adults  man      yes  1      1      1           1\n",
       "2  1st class  adults  man      yes  1      1      1           1\n",
       "3  1st class  adults  man      yes  1      1      1           1\n",
       "4  1st class  adults  man      yes  1      1      1           1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['d'] = np.where((titanic['class'] == '1st class'), 1, 0)\n",
    "titanic['sex_d'] = np.where((titanic['sex'] == 'man'), 1, 0)\n",
    "titanic['age_d'] = np.where((titanic['age'] == 'adults'), 1, 0)\n",
    "titanic['survived_d'] = np.where((titanic['survived'] == 'yes'), 1, 0)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cefa1b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d\n",
       "0    0.270789\n",
       "1    0.624615\n",
       "Name: survived_d, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby('d')['survived_d'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bee11b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27078891257995735"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ey0 = titanic.loc[titanic['d']==0, 'survived_d'].mean()\n",
    "ey0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "084c8838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The naive difference in outcomes is 35.38%\n"
     ]
    }
   ],
   "source": [
    "ey0 = titanic.loc[titanic['d']==0, 'survived_d'].mean()\n",
    "ey1 = titanic.loc[titanic['d']==1, 'survived_d'].mean()\n",
    "\n",
    "diff = ey1 - ey0\n",
    "print(\"The naive difference in outcomes is {:.2%}\".format(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6245478",
   "metadata": {},
   "source": [
    "Note that the later is a biased estimate of the ATE, so next we use subclassification weighting to control for cofounders.\n",
    "\n",
    "*Steps*:\n",
    "\n",
    "1. Stratify the data into four groups: young males, young females, old males, old females.\n",
    "2. Calculate the difference in survival probabilities for each group.\n",
    "3. Calculate the number of people in the non-first-class groups and divide by the total number of non-first-class population. These are our strata-specific weights.\n",
    "4. Calculate the weighted average survival rate using the strata weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84feaf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['s'] = 0 \n",
    "titanic.loc[(titanic.sex_d == 0) & (titanic.age_d==1), 's'] = 1 #woman and adult\n",
    "titanic.loc[(titanic.sex_d == 0) & (titanic.age_d==0), 's'] = 2 #woman and child\n",
    "titanic.loc[(titanic.sex_d == 1) & (titanic.age_d==1), 's'] = 3\n",
    "titanic.loc[(titanic.sex_d == 1) & (titanic.age_d==0), 's'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb989046",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs=len(titanic.loc[titanic.d == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59db4391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg_effect(df):\n",
    "    diff = df[df.d==1].survived_d.mean() - df[df.d==0].survived_d.mean()\n",
    "    weight = len(df[df.d==0])/obs\n",
    "    return diff*weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8220f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weigthted average treatment effect estimate is 18.88%\n"
     ]
    }
   ],
   "source": [
    "wate = titanic.groupby('s').apply(weighted_avg_effect).sum()\n",
    "print(\"The weigthted average treatment effect estimate is {:.2%}\".format(wate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db8fd3f",
   "metadata": {},
   "source": [
    "### 2.4. Course of dimensionality\n",
    "\n",
    "What if the cofounder has multiple values? For example, what if instead of stratifying the data in adult or child (binary), we stratify for all age-values possible?\n",
    "\n",
    "![title](Material/table5.png)\n",
    "\n",
    "Here the common support assumption is being violated, since there are not any 12-year-old male passengers in first class, nor are there any 14-year-old male passengers in first class. Thus, we cannot estimate the ATE, since our stratifying variable has too many dimensions.\n",
    "\n",
    "However, you could calculate the ATT if there is always someone in the control group for a given combination of gender and age, like 11-years-old and 13-years-old in the example above.\n",
    "\n",
    "$\\hat{\\delta}_{ATT}= \\sum_{k=1}^{K}(\\bar{Y}^{1,k} - \\bar{Y}^{0,k})  (\\frac{N^{k}_{T}}{N_{T}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb722965",
   "metadata": {},
   "source": [
    "## 3. Exact Matching\n",
    "\n",
    "What if we filled in the missing potential outcome for each treatment unit using a control group unit that was “closest” to the treatment group unit for some $X$ confounder? This approach is called matching and there exist exact and approximate matching.\n",
    "\n",
    "A simple matching estimator is the following:\n",
    "\n",
    "$\\hat{\\delta}_{ATT}= \\frac{1}{{N_T}} \\sum_{D_i=1} (Y_i- Y_{j(i)})$\n",
    "\n",
    "where $Y_{j(i)}$ is the jth unit matched to the ith unit based on the idea that the jth unit is the closest to the ith unit given certain covariate. In the case where many units matches ith, we would assign the average outcome $\\frac{1}{M}$ as the conterfactual.\n",
    "\n",
    "$\\hat{\\delta}_{ATT}= \\frac{1}{{N_T}} \\sum_{D_i=1} (Y_i- [\\frac{1}{M} \\sum_{m=1}^{M}Y_{jm(1)}])$\n",
    "\n",
    "We can estimate the ATE by filling both missing control group units.\n",
    "\n",
    "$\\hat{\\delta}_{ATE}= \\frac{1}{{N}} \\sum_{i=1}^{N} (2D_i -1) (Y_i- [\\frac{1}{M} \\sum_{m=1}^{M}Y_{jm(1)}])$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afa0093b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_treat</th>\n",
       "      <th>age_treat</th>\n",
       "      <th>earnings_treat</th>\n",
       "      <th>unit_control</th>\n",
       "      <th>age_control</th>\n",
       "      <th>earnings_control</th>\n",
       "      <th>unit_matched</th>\n",
       "      <th>age_matched</th>\n",
       "      <th>earnings_matched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>12250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10075.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8725.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11750</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>12775.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10075.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>13250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12550.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11425.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_treat  age_treat earnings_treat  unit_control  age_control  \\\n",
       "0         1.0       18.0           9500           1.0         20.0   \n",
       "1         2.0       29.0          12250           2.0         27.0   \n",
       "2         3.0       24.0          11000           3.0         21.0   \n",
       "3         4.0       27.0          11750           4.0         39.0   \n",
       "4         5.0       33.0          13250           5.0         38.0   \n",
       "\n",
       "   earnings_control  unit_matched  age_matched  earnings_matched  \n",
       "0            8500.0           1.0         18.0            8050.0  \n",
       "1           10075.0           2.0         29.0           10525.0  \n",
       "2            8725.0           3.0         24.0            9400.0  \n",
       "3           12775.0           4.0         27.0           10075.0  \n",
       "4           12550.0           5.0         33.0           11425.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_stata(\"Data/training_example.dta\")\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b398361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caroa\\anaconda3\\lib\\site-packages\\plotnine\\layer.py:324: PlotnineWarning: stat_bin : Removed 14 rows containing non-finite values.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (147561751787)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.ggplot(training_data, p.aes(x='age_treat')) +  p.stat_bin(bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "555b486a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caroa\\anaconda3\\lib\\site-packages\\plotnine\\layer.py:324: PlotnineWarning: stat_bin : Removed 4 rows containing non-finite values.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (147562355300)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.ggplot(training_data, p.aes(x='age_control')) +  p.geom_histogram(bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e8d925",
   "metadata": {},
   "source": [
    "*should we add this at all? or just leave as theory (equations)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb8772",
   "metadata": {},
   "source": [
    "## 4. Approximate matching\n",
    "\n",
    "### 4.1. Nearest neighbor covariate matching\n",
    "\n",
    "When the number of matching covariates is more than one, we need a new definition of distance to measure closeness between units of observation. \n",
    "\n",
    "* **Euclidean distance**:\n",
    "\n",
    "\\begin{align*}\n",
    "|| X_i - X_j|| & = \\sqrt{(X_i - X_j)' (X_i-X_j)} \\\\\n",
    "&=  \\sqrt{\\sum_{n=1}^{k}(X_{ni} - X_{nj})^2}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "* **Normalized Euclidean distance**, a commonly used distance, and what makes it different is that the distance of each variable is scaled by the variable’s variance:\n",
    "\n",
    "$|| X_i - X_j|| = \\sqrt{\\sum_{n=1}^{k} \\frac{(X_{ni} - X_{nj})}{\\hat{\\sigma_n}^2}}$\n",
    "\n",
    "* **Mahalanobis distance**, another scale-invariant metric:\n",
    "\n",
    "$|| X_i - X_j|| = \\sqrt{(X_i - X_j)' \\hat{\\sum_{X}^{-1}} (X_i-X_j)}$\n",
    "\n",
    "where $\\hat{\\sum_{X}^{-1}}$ is the variance-covariance matrix of $X$.\n",
    "\n",
    "The problem with this is that we can introduce discrepancies; that is, when $X_i$ is not equal to $X_j$. Here, the difference is called bias, and it can be large, small or close to zero. For large samples, the bias tend to converge to zero. Hoewever, the larger the dimension, the greater likelihood of matching discrepancies, and the more data is needed.\n",
    "\n",
    "### 4.2. Bias Correction\n",
    "\n",
    "Bias derivation:\n",
    "\n",
    "$\\hat{\\delta}_{ATT}= \\frac{1}{N_T} \\sum_{D_i=1}(Y_i-Y_{j(i)})$\n",
    "\n",
    "$\\mu^0(x)=E[Y|X=x, D=0]=E[Y^0|X=x]$\n",
    "\n",
    "$\\mu^1(x)=E[Y|X=x, D=1]=E[Y^1|X=x]$\n",
    "\n",
    "where the observed value is a function of expected conditional outcomes and some stochastic element:\n",
    "\n",
    "$Y_i=\\mu^{D_i}(X_i) + \\varepsilon_i$\n",
    "\n",
    "rewriting the ATT estimator we get:\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{\\delta}_{ATT} & =\\frac{1}{N_T}\\sum_{D_i=1}((\\mu^{1}(X_i) + \\varepsilon_i) - (\\mu^{0}(X_{j(i)}) + \\varepsilon_{j(i)})) \\\\\n",
    "& =\\frac{1}{N_T}\\sum_{D_i=1}(\\mu^{1}(X_i) - \\mu^{0}(X_{j(i)}) + \\frac{1}{N_T}\\sum_{D_i=1} (\\varepsilon_i - \\varepsilon_{j(i)})\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Now lets compare the estimator with the true value of ATT:\n",
    "\\begin{align*}\n",
    "\\hat{\\delta}_{ATT} - \\delta_{ATT} & = \\frac{1}{N_T}\\sum_{D_i=1}(\\mu^{1}(X_i) - \\mu^{0}(X_{j(i)}) - \\delta_{ATT} + \\frac{1}{N_T}\\sum_{D_i=1} (\\varepsilon_i - \\varepsilon_{j(i)}) \\\\\n",
    "&=  \\frac{1}{N_T}\\sum_{D_i=1}(\\mu^{1}(X_i) - \\mu^{0}(X_{j(i)}) - \\delta_{ATT}) + \\frac{1}{N_T}\\sum_{D_i=1} (\\varepsilon_i - \\varepsilon_{j(i)}) + \\frac{1}{N_T}\\sum_{D_i=1}(\\mu^{0}(X_i) - \\mu^{0}(X_{j(i)})\n",
    "\\end{align*}\n",
    "\n",
    "$E[\\sqrt{N_T}(\\hat{\\delta}_{ATT} - \\delta_{ATT})]=E[\\sqrt{N_T}(\\mu^{0}(X_i) - \\mu^{0}(X_{j(i)}| D=1]$\n",
    "\n",
    "Consider when the number of covariates is large. Then:\n",
    "\n",
    "* The difference between $X_i$ and $X_j(i)$ converges to zero slowly.\n",
    "\n",
    "* $\\mu^{0}(X_i) - \\mu^{0}(X_{j(i)})$ converges slowly to zero.\n",
    "\n",
    "* $E[\\sqrt{N_T}(\\mu^{0}(X_i) - \\mu^{0}(X_{j(i)}| D=1]$ may not converge to zero.\n",
    "\n",
    "* $E[\\sqrt{N_T}(\\hat{\\delta}_{ATT}- \\delta_{ATT})]$ may not converge to zero.\n",
    "\n",
    "Note that the total bias is made up of the bias associated with each individual unit $i$. This means that each treated observation contributes $\\mu^{0}(X_i) - \\mu^{0}(X_{j(i)})$ to the overall bias. The bias corrected estimator following Abadie and Imbens (2011) is then:\n",
    "\n",
    "$\\frac{1}{N_T}\\sum_{D_i=1}[(Y_i - Y_{j(i)}) - \\hat{\\mu}^{0}(X_i) - \\hat{\\mu}^{0}(X_{j(i)})]$\n",
    "\n",
    "where one could use OLS to estimate $\\hat{\\mu}^{0}(X)$\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81d43393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit</th>\n",
       "      <th>Y</th>\n",
       "      <th>D</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unit   Y  D   X\n",
       "0     1   5  1  11\n",
       "1     2   2  1   7\n",
       "2     3  10  1   5\n",
       "3     4   6  1   3\n",
       "4     5   4  0  10\n",
       "5     6   0  0   8\n",
       "6     7   5  0   4\n",
       "7     8   1  0   1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_bias_reduc = pd.read_stata(\"Data/training_bias_reduction.dta\")\n",
    "training_bias_reduc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e9d337a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit</th>\n",
       "      <th>Y</th>\n",
       "      <th>D</th>\n",
       "      <th>X</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unit   Y  D   X  Y1  Y0\n",
       "0     1   5  1  11   1   4\n",
       "1     2   2  1   7   1   0\n",
       "2     3  10  1   5   1   5\n",
       "3     4   6  1   3   1   1\n",
       "4     5   4  0  10   0   4\n",
       "5     6   0  0   8   0   0\n",
       "6     7   5  0   4   0   5\n",
       "7     8   1  0   1   0   1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_bias_reduc['Y1'] = 0\n",
    "training_bias_reduc.loc[training_bias_reduc['Unit'].isin(range(1,5)), 'Y1'] = 1\n",
    "training_bias_reduc['Y0'] = (4,0,5,1,4,0,5,1)\n",
    "training_bias_reduc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddb7530e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y0</th>\n",
       "      <th>Y</th>\n",
       "      <th>D</th>\n",
       "      <th>X</th>\n",
       "      <th>u_hat0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3.888071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4.082474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.179676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.276878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.936672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4.033873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.228277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.374080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unit  Y1  Y0   Y  D   X    u_hat0\n",
       "0     1   1   4   5  1  11  3.888071\n",
       "1     2   1   0   2  1   7  4.082474\n",
       "2     3   1   5  10  1   5  4.179676\n",
       "3     4   1   1   6  1   3  4.276878\n",
       "4     5   0   4   4  0  10  3.936672\n",
       "5     6   0   0   0  0   8  4.033873\n",
       "6     7   0   5   5  0   4  4.228277\n",
       "7     8   0   1   1  0   1  4.374080"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reg = sm.OLS.from_formula('Y ~ X', training_bias_reduc).fit()\n",
    "training_bias_reduc['u_hat0'] = train_reg.predict(training_bias_reduc)\n",
    "training_bias_reduc = training_bias_reduc[['Unit', 'Y1', 'Y0', 'Y', 'D', 'X', 'u_hat0']]\n",
    "training_bias_reduc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930c8033",
   "metadata": {},
   "source": [
    "### 5. Propensity score methods\n",
    "\n",
    "The key idea behind propensity score methods is to compare units who, based on observables, had very similar probabilities of being placed into the treatment group even though those units differed with regard to actual treatment assignment. If conditional on any covariate, two units have the same probability of being treated, then one can say they have similar propensity scores, and all remaining variation in treatment assignment is random. Then, if also the CIA assumption credibly holds, then differences between their observed outcomes are attributable to the treatment.\n",
    "\n",
    "#### 5.1. Example\n",
    "\n",
    "The National Supported Work Demonstration (NSW) job-training program was a temporary employment program designed to help disadvantaged workers lacking basic job skills move into the labor market by giving them work experience and counseling in a sheltered environment.\n",
    "\n",
    "The independence assumption in the NSW holds since it was randomized program, so calculating the treatment effect would be just a simple difference in means. Treatment group participants’ real earnings post-treatment in 1978 were more than earnings of the control group by approximately USD 900 (Lalonde 1986) to USD 1,800 (Dehejia and Wahba 2002), depending on the sample the researcher used.\n",
    "\n",
    "Lalonde 1986 reviewed several econometric methods using data from the experimental control group and other sources of data for nonexperimental control groups (CPS and PSID) and compare them. The results show that there is a big difference between using the experimental control group and nonexperimental control groups for comparison. \n",
    "\n",
    "![title](Material/table6.png)\n",
    "\n",
    "The reason is because of selection bias:\n",
    "\n",
    "$E[Y^0|D=1] \\neq E[Y^0|D=0]$\n",
    "\n",
    "Also, the two groups (treatment and nonexperimental group) seem to be *not exchangeable* in covariates:\n",
    "\n",
    "![title](Material/table7.png)\n",
    "\n",
    "Lets now calculate the ATE using the NSW data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "280bf405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experimental ATE estimate is 1794.35\n"
     ]
    }
   ],
   "source": [
    "nsw_dw = pd.read_stata('Data/nsw_mixtape.dta')\n",
    "mean1 = nsw_dw[nsw_dw.treat==1].re78.mean()\n",
    "mean0 = nsw_dw[nsw_dw.treat==0].re78.mean()\n",
    "ate = np.unique(mean1 - mean0)[0]\n",
    "print(\"The experimental ATE estimate is {:.2f}\".format(ate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ca423c",
   "metadata": {},
   "source": [
    "Now, instead of calculating the ATE using the NSW data, lets use the CPS data, so now the control group consists of a random sample of Americans from that time period, whereas the treatment group belongs to an experimental group. Thus, the control group suffers from extreme selection bias since most Americans would not function as counterfactuals for the distressed group of workers who selected into the NSW program.\n",
    "\n",
    "We can use propensity score matching as an improvement in estimating treatment effects using non-experimental data. Following Dehejia and Wahba (2002), we will append the CPS data to the experimental data and estimate the **propensity score** using logit. \n",
    "\n",
    "We use the estimated coefficients from the logit model to estimate the conditional probability of treatment:\n",
    "\n",
    "$Pr(D=1|X)=F(\\beta_0 + \\gamma Treat + \\alpha X)$\n",
    "\n",
    "where $F()=\\frac{e}{(1+e)}$\n",
    "\n",
    "The definition of the propensity score is the selection probability conditional on the confounding variables\n",
    "\n",
    "$p(X)=Pr(D=1|X)$\n",
    "\n",
    "Recall our two assumptions: 1) CIA; 2) Common Support. The CIA assumption is not testable, but common support is testable by simply plotting histograms or summarizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7d2a17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "treat\n",
       "0.0    0.009212\n",
       "1.0    0.190701\n",
       "Name: pscore, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsw_dw_cpscontrol = pd.read_stata('Data/cps_mixtape.dta')\n",
    "\n",
    "nsw_dw_cpscontrol = pd.concat((nsw_dw_cpscontrol, nsw_dw))\n",
    "nsw_dw_cpscontrol[['u74', 'u75']] = 0\n",
    "nsw_dw_cpscontrol.loc[nsw_dw_cpscontrol.re74==0, 'u74'] = 1\n",
    "nsw_dw_cpscontrol.loc[nsw_dw_cpscontrol.re75==0, 'u75'] = 1\n",
    "\n",
    "# estimating propensity score\n",
    "logit_nsw = smf.glm(formula=\"\"\"treat ~ age + age**2 + age**3 + educ + educ**2 + \n",
    "                    marr + nodegree + black + hisp + re74 + re75 + u74 + u75 + educ*re74\"\"\", \n",
    "                    family=sm.families.Binomial(),\n",
    "                   data=nsw_dw_cpscontrol).fit()\n",
    "                  \n",
    "nsw_dw_cpscontrol['pscore'] = logit_nsw.predict(nsw_dw_cpscontrol)\n",
    "\n",
    "nsw_dw_cpscontrol.groupby('treat')['pscore'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87f8829e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caroa\\anaconda3\\lib\\site-packages\\plotnine\\facets\\facet.py:390: PlotnineWarning: If you need more space for the x-axis tick text use ... + theme(subplots_adjust={'wspace': 0.25}). Choose an appropriate value for 'wspace'.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (147562639153)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.ggplot(nsw_dw_cpscontrol, p.aes(x='pscore')) +    p.geom_histogram(bins=50) +    p.facet_wrap(\"treat\", scales='free')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0f2e025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "treat      \n",
       "0.0    0.01    0.000040\n",
       "       0.05    0.000046\n",
       "       0.10    0.000053\n",
       "       0.25    0.000091\n",
       "       0.50    0.000380\n",
       "       0.75    0.002481\n",
       "       0.90    0.010569\n",
       "       0.95    0.029357\n",
       "       0.99    0.287441\n",
       "1.0    0.01    0.001923\n",
       "       0.05    0.005709\n",
       "       0.10    0.011148\n",
       "       0.25    0.086148\n",
       "       0.50    0.195483\n",
       "       0.75    0.313613\n",
       "       0.90    0.343488\n",
       "       0.95    0.354946\n",
       "       0.99    0.364708\n",
       "Name: pscore, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (nsw_dw_cpscontrol.groupby('treat')['pscore']\n",
    "        .quantile([.01,.05,.1,.25,.5,.75,.90,.95, .99]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "699436ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "treat\n",
       "0.0    0.009212\n",
       "1.0    0.190701\n",
       "Name: pscore, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsw_dw_cpscontrol.groupby('treat')['pscore'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5e2ae0",
   "metadata": {},
   "source": [
    "How to interpret the large mass of nearly zero propensity scores in the histogram?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecee29d",
   "metadata": {},
   "source": [
    "The treatment parameter under the CIA and Common support assumption is:\n",
    "\n",
    "\\begin{align*}\n",
    "E[\\delta_i(X_i)] & =E=[Y_{i}^1 - Y_{i}^0| X_i=x] \\\\\n",
    "&= E[Y_{i}^1|X_i=x]-E[Y_{i}^0|X_i=x]\n",
    "\\end{align*}\n",
    "\n",
    "The CIA allows to:\n",
    "\n",
    "$E[Y_{i}^1|D_i=1, X_i=x]= E[Y_{i}|D_i=1, X_i=x]$\n",
    "\n",
    "so under both assumptions:\n",
    "\n",
    "$\\delta=E[\\delta_i(X_i)]$\n",
    "\n",
    "The *propensity score theorem* states that under the CIA this yields:\n",
    "\n",
    "$(Y^1, Y^0) \\perp D| p(X)$\n",
    "\n",
    "where $p(X)$ is the propensity score.\n",
    "\n",
    "**Proof of the propensity score**\n",
    "\n",
    "\\begin{align*}\n",
    "Pr(D=1|Y^1, Y^0, p(X))& =E[D|Y^1, Y^0, p(X)] \\\\\n",
    "&=\\underbrace{E[E[D|Y^1, Y^0, p(X), X]|Y^1, Y^0, p(X)]}_{by \\: LIE} \\\\\n",
    "&=\\underbrace{E[E[D|Y^1, Y^0, X]|Y^1, Y^0, p(X)]}_{given \\: X \\: we \\: know \\: p(X)} \\\\\n",
    "&=\\underbrace{E[E[D|X]|Y^1, Y^0, p(X)]}_{by \\: conditional \\: independence} \\\\\n",
    "&=\\underbrace{E[p(X)|Y^1, Y^0, p(X)]}_{propensity \\: score \\: definition} \\\\\n",
    "&=p(X)\n",
    "\\end{align*}\n",
    "\n",
    "proceeding similarly, we get:\n",
    "\n",
    "\\begin{align*}\n",
    "Pr(D=1|p(X))& =\\underbrace{E[D|p(X)]}_{previous \\: argument} \\\\\n",
    "&=\\underbrace{E[E[D|X]|p(X)]}_{LIE} \\\\\n",
    "&=\\underbrace{E[p(X)|p(X)]}_{definition} \\\\\n",
    "&=p(X)\n",
    "\\end{align*}\n",
    "\n",
    "where $Pr(D=1|Y^1, Y^0, p(X))=Pr(D=1|p(X))$ by CIA assumption.\n",
    "\n",
    "The propensity score theorem says:\n",
    "\n",
    "* control for covariates that determine the likelihood a unit receives the treatment.\n",
    "* the only covariate to condition on is the propensity score.\n",
    "\n",
    "The balancing property of the propensity score is:\n",
    "\n",
    "$Pr(X|D=1, p(X))=Pr(X|D=0, p(X))$ and says that, conditional on the propensity score, the distribution of the covariates is the same for the treatment as it is for the control group.\n",
    "\n",
    "![title](Material/image1.png)\n",
    "\n",
    "### 5.2. Weighting on the propensity score\n",
    "\n",
    "Assuming that CIA holds in our data, one way we can estimate treatment effects is to use a weighting procedure in which each individual’s propensity score is a weight of that individual’s outcome. When aggregated, this has the potential to identify some average treatment effect. \n",
    "\n",
    "\\begin{align*}\n",
    "\\delta_{ATE}& =E[Y^1-Y^0] \\\\\n",
    "&=E[Y  \\frac{D-p(X)}{p(X)(1-p(X)}]\\\\\n",
    "\\delta_{ATT}& =E[Y^1-Y^0|D=1] \\\\\n",
    "&=\\frac{1}{Pr(D=1)}E[Y  \\frac{D-p(X)}{(1-p(X)}]\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Both ATE and ATT sample versions are estimated by a two-step estimation.\n",
    "\n",
    "1) Estimate propensity score using logit or probit.\n",
    "2) Use the estimated score to produce sample versions of one of the average treatment effect estimators shown above.\n",
    "\n",
    "$\\hat{\\delta}_{ATE}=\\frac{1}{N} \\sum_{i=1}^{N} \\frac{D_i-\\hat{p}(X_i)}{\\hat{p}(X_i)(1-\\hat{p}(X_i))}$\n",
    "\n",
    "$\\hat{\\delta}_{ATT}=\\frac{1}{N_T} \\sum_{i=1}^{N} \\frac{D_i-\\hat{p}(X_i)}{1-\\hat{p}(X_i)}$\n",
    "\n",
    "The sensitivity of inverse probability weighting to extreme values of the propensity score has led some researchers to propose an alternative that can handle extremes a bit better.\n",
    "\n",
    "$\\hat{\\delta}_{ATT}=[\\sum_{i=1}^{N} \\frac{Y_iD_i}{p}] / [\\sum_{i=1}^{N} \\frac{D_i}{\\hat{p}}] - [\\sum_{i=1}^{N}\\frac{Y_i(1-D_i)}{1-\\hat{p}}]/[\\sum_{i=1}^{N}\\frac{(1-D_i)}{(1-\\hat{p})}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33544eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment Effect (non-normalized, all data): -11535.55\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for logit \n",
    "nsw_dw_cpscontrol =  pd.read_stata('Data/cps_mixtape.dta')\n",
    "\n",
    "nsw_dw_cpscontrol = pd.concat((nsw_dw_cpscontrol, nsw_dw))\n",
    "nsw_dw_cpscontrol[['u74', 'u75']] = 0\n",
    "nsw_dw_cpscontrol.loc[nsw_dw_cpscontrol.re74==0, 'u74'] = 1\n",
    "nsw_dw_cpscontrol.loc[nsw_dw_cpscontrol.re75==0, 'u75'] = 1\n",
    "# estimating propensity score\n",
    "logit_nsw = smf.glm(formula=\"\"\"treat ~ age + age**2 + age**3 + educ + educ**2 + \n",
    "                    marr + nodegree + black + hisp + re74 + re75 + u74 + u75 + educ*re74\"\"\", \n",
    "                    family=sm.families.Binomial(),\n",
    "                   data=nsw_dw_cpscontrol).fit()\n",
    "                  \n",
    "nsw_dw_cpscontrol['pscore'] = logit_nsw.predict(nsw_dw_cpscontrol)\n",
    "\n",
    "\n",
    "# continuation\n",
    "N = nsw_dw_cpscontrol.shape[0]\n",
    "\n",
    "# Manual with non-normalized weights using all data\n",
    "nsw_dw_cpscontrol = nsw_dw_cpscontrol \n",
    "nsw_dw_cpscontrol['d1'] = nsw_dw_cpscontrol.treat/nsw_dw_cpscontrol.pscore\n",
    "nsw_dw_cpscontrol['d0'] = (1-nsw_dw_cpscontrol.treat)/(1-nsw_dw_cpscontrol.pscore)\n",
    "\n",
    "\n",
    "s1 = nsw_dw_cpscontrol.d1.sum()\n",
    "s0 = nsw_dw_cpscontrol.d0.sum()\n",
    "\n",
    "nsw_dw_cpscontrol['y1'] = nsw_dw_cpscontrol.treat * nsw_dw_cpscontrol.re78 / nsw_dw_cpscontrol.pscore\n",
    "nsw_dw_cpscontrol['y0'] = (1 - nsw_dw_cpscontrol.treat) * nsw_dw_cpscontrol.re78 / (1 - nsw_dw_cpscontrol.pscore)\n",
    "nsw_dw_cpscontrol['ht'] = nsw_dw_cpscontrol['y1'] - nsw_dw_cpscontrol['y0']\n",
    "\n",
    "te_1 = nsw_dw_cpscontrol.ht.mean()\n",
    "\n",
    "print(\"Treatment Effect (non-normalized, all data): {:.2f}\".format(te_1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3910371c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment Effect (normalized, all data): -7044.80\n"
     ]
    }
   ],
   "source": [
    "nsw_dw_cpscontrol['y1'] = nsw_dw_cpscontrol.treat * nsw_dw_cpscontrol.re78 / nsw_dw_cpscontrol.pscore\n",
    "nsw_dw_cpscontrol['y1'] /= s1/N\n",
    "nsw_dw_cpscontrol['y0'] = (1 - nsw_dw_cpscontrol.treat) * nsw_dw_cpscontrol.re78 / (1 - nsw_dw_cpscontrol.pscore)\n",
    "nsw_dw_cpscontrol['y0'] /= s0/N\n",
    "nsw_dw_cpscontrol['ht'] = nsw_dw_cpscontrol['y1'] - nsw_dw_cpscontrol['y0']\n",
    "\n",
    "te_2 = nsw_dw_cpscontrol.ht.mean()\n",
    "\n",
    "print(\"Treatment Effect (normalized, all data): {:.2f}\".format(te_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f927a0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment Effect (non-normalized, trimmed data): 2486.22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nsw_dw_trimmed = nsw_dw_cpscontrol.drop(['d1', 'd0', 'y1', 'y0'], axis=1)\n",
    "nsw_dw_trimmed = nsw_dw_trimmed[nsw_dw_trimmed.pscore.between(.1, .9)]\n",
    "N = nsw_dw_trimmed.shape[0]\n",
    "\n",
    "nsw_dw_trimmed['y1'] = nsw_dw_trimmed.treat * nsw_dw_trimmed.re78 / nsw_dw_trimmed.pscore\n",
    "nsw_dw_trimmed['y0'] = (1 - nsw_dw_trimmed.treat) * nsw_dw_trimmed.re78 / (1 - nsw_dw_trimmed.pscore)\n",
    "nsw_dw_trimmed['ht'] = nsw_dw_trimmed['y1'] - nsw_dw_trimmed['y0']\n",
    "\n",
    "te_3 = nsw_dw_trimmed.ht.mean()\n",
    "\n",
    "print(\"Treatment Effect (non-normalized, trimmed data): {:.2f}\".format(te_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66af21d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment Effect (normalized, trimmed data): 423.62\n"
     ]
    }
   ],
   "source": [
    "nsw_dw_trimmed['y1'] = nsw_dw_trimmed.treat * nsw_dw_trimmed.re78 / nsw_dw_trimmed.pscore\n",
    "nsw_dw_trimmed['y1'] /= s1/N\n",
    "nsw_dw_trimmed['y0'] = (1 - nsw_dw_trimmed.treat) * nsw_dw_trimmed.re78 / (1 - nsw_dw_trimmed.pscore)\n",
    "nsw_dw_trimmed['y0'] /= s0/N\n",
    "nsw_dw_trimmed['ht'] = nsw_dw_trimmed['y1'] - nsw_dw_trimmed['y0']\n",
    "\n",
    "te_4 = nsw_dw_trimmed.ht.mean()\n",
    "\n",
    "print(\"Treatment Effect (normalized, trimmed data): {:.2f}\".format(te_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270211d7",
   "metadata": {},
   "source": [
    "### 5.3. Nearest-neighbor matching\n",
    "\n",
    "Nearest-neighbor matching using the propensity score pairs each treatment unit $i$ with one or more comparable control group units $j$, where comparability is measured in terms of distance to the nearest propensity score.\n",
    "\n",
    "$\\widehat{ATT}=\\frac{1}{N_t}(Y_i-Y_{i(j)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414533b7",
   "metadata": {},
   "source": [
    "### 5.4. Coarsened exact matching (CEM)\n",
    "\n",
    "This is a kind of exact matching that allows to do exact matching one you coarsed the data enough.  Once we find those matches, we calculate weights on the basis of where a person fits in some strata, and those weights are used in a simple weighted regression.\n",
    "\n",
    "How its done:\n",
    "\n",
    "1. Begin with $X$ covariates and create $X*$ which is a copy of $X$.\n",
    "2. Coarsen $X*$: For example, schooling becomes less than high school, high school only, some college, college graduate, post college.\n",
    "3. Create stratums and place each observation of $X*$ into a stratum.\n",
    "4. Assign these strata to the original and uncoarsened data,$X$.\n",
    "5. Drop any observation whose stratum doesn’t contain at least one treated and control unit.\n",
    "6. Add weights for stratum size and analyze without matching.\n",
    "\n",
    "CEM is part of a class of matching methods called monotonic imbalance bounding (MIB), that bound the maximum imbalance in some feature of the empirical distributions by an ex ante decision by the user. By choosing the coarsening beforehand, users can control the amount of imbalance in the matching solution.\n",
    "\n",
    "$L1(f,g)=\\frac{1}{2} \\sum_{l1,...,lk} |f_{l1...lk}-g_{l1...lk}|$\n",
    "\n",
    "where perfect global is L1=0 and L1=1 maximum imbalance.\n",
    "\n",
    "# 6. Conclusions\n",
    "\n",
    "* The propensity score can make groups comparable, but only on the variables used to estimate the propensity score in the first place.\n",
    "\n",
    "* Every matching solution to a causality problem requires a credible belief that the backdoor criterion can be achieved by conditioning on some matrix $X$, or what we’ve called CIA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
